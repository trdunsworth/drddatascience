<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Dr. D&#39;s Data Science</title>
<link>https://drddatascience.com/blog.html</link>
<atom:link href="https://drddatascience.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>Public Safety Data Science by Dr. Tony Dunsworth</description>
<generator>quarto-1.6.40</generator>
<lastBuildDate>Sun, 02 Feb 2025 05:00:00 GMT</lastBuildDate>
<item>
  <title>So where does the data take me?</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/20250128/</link>
  <description><![CDATA[ 




<section id="reflections-about-the-last-week" class="level1">
<h1>Reflections about the last week</h1>
<p>I just finished a week at <a href="https://nena.org">NENA’s</a> Standard and Best Practices. I had a wonderful time with my presentations on developing staffing models, data management, and using data better in call processing. I met a lot of new friends and I see a lot of opportunities ahead of me to make a real difference at the intersection of public safety and data science.</p>
<section id="nenas-sbp" class="level2">
<h2 class="anchored" data-anchor-id="nenas-sbp">NENA’s SBP</h2>
<p>I participated in seven presentations. I will upload slide decks and notes later for people who are interested in learning what I was talking about in detail.</p>
<section id="staffing" class="level3">
<h3 class="anchored" data-anchor-id="staffing">Staffing</h3>
<p>Three of these were in a block discussing the need for a new staffing model recommendation in 911 centres. Currently, NENA’s <a href="https://cdn.ymaws.com/www.nena.org/resource/resmgr/standards/NENA-REF-001-2003_PSAP_Staff.pdf">Staffing Recommendations</a> are over 21 years old and rely heavily on the <a href="https://myweb.ecu.edu/robbinst/PDFs/Erlang%20Compare%20Working%20paper.pdf">Erlang-C</a> model for staffing recommendations. There has been a tonne of work in queuing theory since the development of this formula. And, as referenced in the linked paper, there are legitimate questions about how appropriate the Erlang model family is for regular call centres, let alone 911 centres.</p>
<p>One of the central problems is that Erlang-C models assume there is only one queue that delivers all of the customers to the servers. In most modern centres, there are at least 4 ingression points to the server set. We have dedicated 9-1-1 trunk lines, typically most primary PSAPs also answer some non-emergency lines, and most centres also take 9-1-1 SMS messages. Finally, all centres have to be able to receive and process TTD-TTY calls. Many larger centers may also process traffic cameras, <a href="https://www.apcointl.org/technology/interoperability/asap-to-psap/">ASAP2PSAP</a> generated alarm calls, or other monitoring services like <a href="https://www.soundthinking.com/">ShotSpotter</a>. Dispatchers also have radio traffic from the units that they monitor which require their attention. So, there are numerous queues to access the servers, the servers are all multi-skilled servers, and the different queues have different priorities for servers depending on skill sets and responsibilities. Each of these adds levels of complexity that could confound an Erlang-C model.</p>
<p>There are several different methods that could come into play, including Markovian models, Game Theory, and Priority Queuing Models. Each of these can be explored and addressed.</p>
<p>I remain convinced that we have enough brain power in NENA that our working group can tackle this issue and come up with a queuing model that will work for the industry.</p>
</section>
<section id="eido-and-ng9-1-1" class="level3">
<h3 class="anchored" data-anchor-id="eido-and-ng9-1-1">EIDO and NG9-1-1</h3>
<p>Two of the other presentations centered around the <a href="https://cdn.ymaws.com/www.nena.org/resource/resmgr/standards/NENA-STA-021.1b-2021_2024121.pdf">Emergency Incident Data Object</a>. This is how, we propose, to move information between different systems and entities in public safety. It’s in a <a href="https://www.json.org/json-en.html">JSON</a> object that leverages <a href="https://www.niem.gov/about-niem">NIEM</a> to define the objects passed between entities. My presentations dicussed the JSON object itself and the conveyance mechanisms by which the JSON objects are moved between entities.</p>
<p>I believe in the use of the EIDO as we continue to roll out NG9-1-1 services across the country. We have done a lot of good work throughout the years to create something that can be useful in ensuring data gets to where it needs to go and can be processed efficiently.</p>
</section>
<section id="data-usage" class="level3">
<h3 class="anchored" data-anchor-id="data-usage">Data Usage</h3>
<p>The other presentations in which I participated were the Call Processing working group where I am the <em>‘data SME’</em> and the <a href="https://www.nena.org/page/standards#FutureThink">Future Think</a> committee’s Data Management and Presentation work. That was a fun panel discussion with a lot of great audience participation. There is a general agreement that we need to use more of our data and use it more effectively.</p>
<p>I am heartened, as a data scientist working in public safety, to hear my colleagues in public safety acknowledging the need to use data analytics, regression modeling, predictive analytics, and forecasting to improve things for telecommunicators.</p>
<p>There is also a movement to start considering a shared data repository for research and analytical purposes. I beieve that will be an excellent idea. If we can get several PSAPs together and build out a research database, we could put it in front of other researchers and see where it leades us.</p>
<section id="editorial-note" class="level4">
<h4 class="anchored" data-anchor-id="editorial-note">Editorial Note</h4>
<p><em>I changed the link for NIEM to go to the About page to give readers a better explanaiton of what NIEM is and why it’s important. I also linked to a page describing JSON in better terms. Finally, my editor found a spelling error that was also corrected.</em></p>


</section>
</section>
</section>
</section>

 ]]></description>
  <category>news</category>
  <category>editorial</category>
  <category>data science</category>
  <guid>https://drddatascience.com/posts/20250128/</guid>
  <pubDate>Sun, 02 Feb 2025 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Thoughts While Checking My Language Skills</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/20250129/</link>
  <description><![CDATA[ 




<p>I had a post idea all lined up and then something new landed in my lap. Well, more accurately, it landed in my inbox. I have been tasked with providing some aggregates and means for certain service calls. When I’m looking through some collected data to give me the baseline, I realized that I have four separate columns in my dataset that could be used as the starting timestamp. Many of the rows in the dataset have identical values in all 4 columns. For the rows that don’t, there can be differences between columns of up to 45 seconds. When I asked the requester if there was a preference for which column to use and I received explanations about how further research should be left for operations. I’m ok with that. Ultimately, I was able to learn that there was no preference and I am free to select the starting point I wish.</p>
<p>However, it did get me thinking. I want to know if there is a specific timestamp that <em>should</em> be used as the starting point? Can that be determined statistically? I know that I can create SQL to isolate the earliest time point when there is a discrepancy. However, this could be an interesting project. So, I think I’m going to design it and work on it a bit.</p>



 ]]></description>
  <category>news</category>
  <category>thoughts</category>
  <guid>https://drddatascience.com/posts/20250129/</guid>
  <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
</item>
<item>
  <title>So where does the data take me?</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/20250106/</link>
  <description><![CDATA[ 




<p>With the snow storm that moved from the midwest over the Appalachians and through Virginia, I received texts and a phone call from a friend and former colleague. She asked if I knew of a way to view all of the current calls for service throughout the state. No, she’s not crazy, she was investigating a request made of her. However, the commiunication started me thinking about an <em>“end-to-end”</em> data science solution that could make that a reality.</p>
<p>Thwew are severak steps that need to be taken to create such an application. Granted, the end result would be focused</p>



 ]]></description>
  <category>news</category>
  <category>full-stack</category>
  <category>data science</category>
  <guid>https://drddatascience.com/posts/20250106/</guid>
  <pubDate>Mon, 06 Jan 2025 05:00:00 GMT</pubDate>
</item>
<item>
  <title>So where does the data take me?</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/20250105/</link>
  <description><![CDATA[ 




<p>So, over the <em>dead</em> week between Christmas and New Year’s Day, I started working on a new reporting template. The goal is to create a new archive of weekly and monthly reports for my 911 centre in a <a href="https://quarto.org">Quarto</a> blog format. Currently, I’m working on a sample report for management to see what the audience will like. I also want to use the sample to illustrate what needs to happen with the reports.</p>
<p>An example of this is in our datasets, we trap the time stamps at various points in the life of the service call. Some of these include the start of the call, when it was available to be dispatched, when the first units were assigned, and when the call was disconnected. In the data cleaning process, we have identified some of the deltas between time stamps come out negative. Obviously, you <strong>cannot</strong> dispatch a call before it enters the queue. This means that when we find them, we have to address them in some fashion.</p>



 ]]></description>
  <category>news</category>
  <category>analytics</category>
  <category>911</category>
  <guid>https://drddatascience.com/posts/20250105/</guid>
  <pubDate>Sun, 05 Jan 2025 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Thanks and Thoughts</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/20241223/</link>
  <description><![CDATA[ 




<p>Well, the site is now live, thanks to Ionos’ technical support. I have to compliment the person who followed up with me today. He helped me get everything taken care of and get the site live and available for you to see. It’s nice to go from working to build it to seeing it out there where everyone else can see it and we can go on this journey together.</p>
<p>I also want to thank <a href="https://beamilz.com">Beartiz Milz</a> for writing an awesome <a href="https://beamilz.com/posts/2022-06-05-creating-a-blog-with-quarto/en/">tutorial</a> that helped me turn my limited knowledge of Quarto and my comfort with R into a website and blog to promote my work in 911 data science. I’m also using her tutorial to build a blog as a vehicle for new reports in my PSAP.</p>
<p>For the last 14 years, I’ve written reports for two different PSAPs and felt like my reports have not illuminated everything that the data has to offer. The weekly and monthly reports have been things I’ve been asked to develop. However, there is always so much more in the data which could be important. Can we use knowledge about what days and hours are busiest change how we schedule telecommunicators? Can we see training oportunities by focusing on how long it takes us to process specific call types? Are there hidden correlations in the data that we’ve been missing because we don’t see them? I’ve thought of these questions forever. Now that I’ve finished my doctorate, I want to spend the time investigating these and other questions.</p>
<p>I think that I can build templates that I can share with other interested PSAPs and we can start building better reporting systems which can, by being served as dashboards and websites, make the reports more responsive while automating the delivery. I want to mke things easier for everyone.</p>
<p>I updated my <a href="https://medium.com/@trdunsworth">Medium</a> site with an annoucement that this blog exists and has become active. I’ve also updated <a href="https://linkedin.com/in/tonyrdunsworth">LinkedIn</a> with a link to that <a href="https://medium.com/@trdunsworth/new-blog-new-goals-same-ol-me-107d3dec8cf6">article</a> and invited my friends and contacts there to add comments and ask questions that can turn into blog posts. I will post this article there too, once I’ve published it.</p>
<p>So, this is where this post ends. I will post something new in a couple of days. I’m going to challenge myself to add some code in the next one to see what happens. I have a couple of ideas in mind.</p>



 ]]></description>
  <category>news</category>
  <category>thoughts</category>
  <category>reports</category>
  <guid>https://drddatascience.com/posts/20241223/</guid>
  <pubDate>Sun, 22 Dec 2024 05:00:00 GMT</pubDate>
</item>
<item>
  <title>The Start of a New Blog</title>
  <dc:creator>Tony Dunsworth</dc:creator>
  <link>https://drddatascience.com/posts/startingpoint/</link>
  <description><![CDATA[ 




<p>This is, for me, a starting point post. I am just starting to develop this site, including this blog, as a way to do several things at once. First and foremost, I want to document my work in public safety communications data science. This is a turning point in my career, transitioning from back-end administration of dispatch systems to data analytics and data science.</p>
<p>Another part of this blog will discuss things I find interesting in tech, especially when it comes to data. For example, I have been working more and more in Python lately and finding tools that I enjoy using because they make my work easier. The top three of late are <a href="https://github.com/astral-sh/uv">uv</a>, <a href="https://duckdb.org/">DuckDB</a>, and <a href="https://fireducks-dev.github.io/">FireDucks</a>. Over time, I will add Jupyter notebooks here so I can document my work with these and other tools.</p>
<p>I also want to learn more about <a href="https://julialang.org/">Julia</a>. So I might experiment with it in notebooks as well here and there and document the experience. However, most of the code that you see here will be in R, because it was the first language that I learned and the one that I feel most comfortable with. That will present its own challenge because many forecasting libraries that I have worked with are only expressed in Python.</p>
<p>There will be some tutorials as I write more and I get more comfortable with writing here and updating the blog and the site. Most of those are going to be geared towards public safety communications. I work with <a href="https://nena.org">NENA</a> on several technical committees and part of that work, for me, focuses on bringing advanced analytics to PSAPs across the country. I also speak a few times a year on this and other topics. I will start blogging about what I have presented after the presentations are done. It will be good review.</p>
<p>I am also fascinated with generating synthetic data for analyses. Right now, I’ve been working with <a href="https://mostly.ai/">Mostly.ai</a> to generate synthetic data for my research work. Due to the nature of the work that I do in centres, I use synthetic data for my presentations and my tutorials. My goal is to work with other libraries to create more realistic data for research purposes. I know that I will write about that in future posts. I’m looking forward to having fun with that exploration.</p>
<p>Many of my posts will be found on my <a href="https://medium.com/@trdunsworth">Medium</a> page. Some of the tutorials may also be found, in the future, on my <a href="https://linkedin.com/in/tonyrdunsworth">LinkedIn</a>. However, I will point my audience here over time because there will be posts here that don’t exist other places so I can promote this place as my prefered publication venue.</p>
<p>Well, I think that this is a good start as a pre-launch blog post.</p>



 ]]></description>
  <category>news</category>
  <guid>https://drddatascience.com/posts/startingpoint/</guid>
  <pubDate>Sun, 22 Dec 2024 05:00:00 GMT</pubDate>
</item>
</channel>
</rss>
